# Methods
Representation

* firing rate models, approximate groups of similarly connected neurons at single units
* attractor states in network, corresponding to bistability of unit firing rates
 * may have 1 or more units firing at elevated rates persistently
* model both the long term memory for words (lexicon) and a dedicated but type-independent memory module
 * lexicon is coded localist, with distince units representing different words; but assume in reality that there is a degree of distributed coding, where word representatiosn share active neurons, representing semantic of other informative relationships between words
  * [need citation for localist lexicon, check Paul's papers]
 * memory module is designed to hava a measure of distributed/overlapping representaiton, in order to ecode conjunctions and context. (cf \cite{Howard2002,Davelaar2005})
* episodes are encoded in theoretically two ways:
 1. in the changes in activation-based plasticity that result from the sequence of activated words and memory units

 + huh

 2. in any persistent activity still in the memory module at list end -- this activity sould preferantially represent/store late list items, and thus be more related to recency effect.  
    * [^ can check this!.. have i already?]

Network structure

Model choices

